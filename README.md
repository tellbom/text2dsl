# APM Text2DSL API

ä¸€ä¸ªåŸºäºFastAPIçš„æœåŠ¡ï¼Œç”¨äºå°†è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸ºElasticsearch DSLï¼Œä¸“é—¨é’ˆå¯¹APMï¼ˆåº”ç”¨æ€§èƒ½ç›‘æ§ï¼‰æ•°æ®è¿›è¡Œä¼˜åŒ–ã€‚æ”¯æŒä¸­è‹±æ–‡æ··åˆæŸ¥è¯¢ï¼Œæ™ºèƒ½æ—¶é—´èŒƒå›´åˆ†æï¼Œå¯ä¸Difyç­‰LLMå¹³å°é›†æˆã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸŒ **å¤šè¯­è¨€æ”¯æŒ**ï¼šæ”¯æŒä¸­è‹±æ–‡æ··åˆæŸ¥è¯¢ï¼Œæ™ºèƒ½è¯­ä¹‰ç†è§£
- ğŸ• **æ—¶åŒºæ„ŸçŸ¥**ï¼šæ”¯æŒå¤šæ—¶åŒºæ—¶é—´èŒƒå›´è§£æï¼Œæ™ºèƒ½æ—¶é—´ä¸Šä¸‹æ–‡åˆ†æ
- ğŸ“Š **APMä¼˜åŒ–**ï¼šä¸“é—¨é’ˆå¯¹Elastic APMæ•°æ®ç»“æ„è®¾è®¡ï¼Œè¦†ç›–æ‰€æœ‰ç›‘æ§åœºæ™¯
- ğŸ”„ **å¤šæ ¼å¼æ”¯æŒ**ï¼šæ”¯æŒJSONã€Markdownç­‰å¤šç§DSLè¾“å…¥æ ¼å¼
- ğŸ³ **å®¹å™¨åŒ–éƒ¨ç½²**ï¼šå®Œæ•´çš„Dockeræ”¯æŒï¼Œç”Ÿäº§çº§é…ç½®
- ğŸ” **è°ƒè¯•å‹å¥½**ï¼šæä¾›å®Œæ•´çš„è°ƒè¯•å’Œè¯Šæ–­API
- ğŸ§  **æ™ºèƒ½DSLç”Ÿæˆ**ï¼šé«˜è´¨é‡çš„æç¤ºè¯å·¥ç¨‹ï¼Œé¿å…å¸¸è§è¯­æ³•é”™è¯¯
- âš¡ **é«˜æ€§èƒ½æŸ¥è¯¢**ï¼šä¼˜åŒ–çš„ESæŸ¥è¯¢æ€§èƒ½å’Œèšåˆç­–ç•¥

## ç³»ç»Ÿæ¶æ„

### ç®€åŒ–å·¥ä½œæµç¨‹
```
ç”¨æˆ·æŸ¥è¯¢ â†’ /generate-dsl â†’ LLMç”ŸæˆDSL â†’ /execute-query â†’ LLMåˆ†æç»“æœ â†’ æœ€ç»ˆå›å¤
```

### æ™ºèƒ½æ—¶é—´æ„ŸçŸ¥å·¥ä½œæµç¨‹
```
ç”¨æˆ·æŸ¥è¯¢ â†’ /analyze-time-context â†’ LLMåˆ†ææ—¶é—´éœ€æ±‚ â†’ /process-time-analysis 
    â†“
/generate-dsl â†’ LLMç”ŸæˆDSL â†’ /execute-query â†’ LLMåˆ†æç»“æœ â†’ æœ€ç»ˆå›å¤
```

### æ ¸å¿ƒç»„ä»¶

1. **æ—¶é—´ä¸Šä¸‹æ–‡åˆ†æ**ï¼šæ™ºèƒ½åˆ¤æ–­æŸ¥è¯¢æ‰€éœ€çš„æœ€ä½³æ—¶é—´èŒƒå›´
2. **DSLç”Ÿæˆå¼•æ“**ï¼šåŸºäºAPMæœ€ä½³å®è·µçš„é«˜è´¨é‡DSLç”Ÿæˆ
3. **æŸ¥è¯¢æ‰§è¡Œå¼•æ“**ï¼šä¼˜åŒ–çš„ElasticsearchæŸ¥è¯¢æ‰§è¡Œ
4. **ç»“æœåˆ†æå¼•æ“**ï¼šä¸“ä¸šçš„APMæ•°æ®è§£è¯»å’Œå»ºè®®

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Docker & Docker Compose
- Elasticsearch 7.x+ (å·²é…ç½®APMæ•°æ®)
- Python 3.10+ (æœ¬åœ°å¼€å‘)
- å†…å­˜: æœ€å°‘512MBï¼Œæ¨è1GB+

### 1. å…‹éš†é¡¹ç›®

```bash
git clone <your-repo-url>
cd apm-text2dsl
```

### 2. é…ç½®ç¯å¢ƒ

ä¿®æ”¹ `main.py` ä¸­çš„ESé…ç½®ï¼š

```python
ES_HOST = "http://your-elasticsearch-host:9200"
```

æˆ–ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼š

```bash
export ES_HOST="http://your-elasticsearch-host:9200"
```

### 3. Dockeréƒ¨ç½²

#### æ„å»ºé•œåƒ

```bash
docker build -t apm-text2dsl:latest .
```

#### è¿è¡Œå®¹å™¨

```bash
# åŸºæœ¬è¿è¡Œ
docker run -d \
  --name apm-text2dsl \
  -p 8000:8000 \
  -e ES_HOST=http://your-elasticsearch:9200 \
  apm-text2dsl:latest

# å¼€å‘æ¨¡å¼ï¼ˆä»£ç æ˜ å°„ï¼‰
docker run -d \
  --name apm-text2dsl \
  -p 8000:8000 \
  -v $(pwd):/app \
  -e ES_HOST=http://your-elasticsearch:9200 \
  apm-text2dsl:latest

# ä½¿ç”¨å®¿ä¸»æœºç½‘ç»œï¼ˆæ¨èï¼‰
docker run -d \
  --name apm-text2dsl \
  --network host \
  -v $(pwd):/app \
  -e ES_HOST=http://localhost:9200 \
  apm-text2dsl:latest

# ç”Ÿäº§ç¯å¢ƒé…ç½®
docker run -d \
  --name apm-text2dsl \
  --restart unless-stopped \
  --memory=1g \
  --cpus=1.0 \
  -p 8000:8000 \
  -e ES_HOST=http://your-elasticsearch:9200 \
  -e TZ=Asia/Shanghai \
  apm-text2dsl:latest
```

### 4. éªŒè¯éƒ¨ç½²

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# æ£€æŸ¥ESè¿æ¥
curl http://localhost:8000/debug/indices

# APIæ–‡æ¡£
æ‰“å¼€æµè§ˆå™¨è®¿é—®: http://localhost:8000/docs
```

## API æ–‡æ¡£

### æ—¶é—´æ„ŸçŸ¥API

#### 1. åˆ†ææ—¶é—´ä¸Šä¸‹æ–‡

**POST** `/analyze-time-context`

æ™ºèƒ½åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œç”Ÿæˆæ—¶é—´èŒƒå›´åˆ†ææç¤ºè¯ã€‚

**è¯·æ±‚ä½“ï¼š**
```json
{
  "query": "æœ€è¿‘ç”¨æˆ·æœåŠ¡æœ‰ä»€ä¹ˆå¼‚å¸¸å—ï¼Ÿ",
  "timezone": "Asia/Shanghai"
}
```

**å“åº”ï¼š**
```json
{
  "prompt": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„APMç›‘æ§æ—¶é—´èŒƒå›´åˆ†æä¸“å®¶...",
  "query_type": "error",
  "original_query": "æœ€è¿‘ç”¨æˆ·æœåŠ¡æœ‰ä»€ä¹ˆå¼‚å¸¸å—ï¼Ÿ"
}
```

#### 2. å¤„ç†æ—¶é—´åˆ†æç»“æœ

**POST** `/process-time-analysis`

å¤„ç†LLMè¿”å›çš„æ—¶é—´åˆ†æç»“æœï¼ŒéªŒè¯å¹¶ç»“æ„åŒ–ã€‚

**è¯·æ±‚ä½“ï¼š**
```json
{
  "content": "```json\n{\"time_range\": \"2h\", \"reasoning\": \"å¼‚å¸¸æŸ¥è¯¢éœ€è¦è¶³å¤Ÿçš„æ•°æ®æ ·æœ¬\", \"confidence\": \"high\"}\n```"
}
```

**å“åº”ï¼š**
```json
{
  "time_range": "2h",
  "reasoning": "å¼‚å¸¸æŸ¥è¯¢éœ€è¦è¶³å¤Ÿçš„æ•°æ®æ ·æœ¬",
  "confidence": "high",
  "original_query": ""
}
```

### æ ¸å¿ƒAPI

#### 3. ç”ŸæˆDSLæç¤ºè¯

**POST** `/generate-dsl`

æ ¹æ®ç”¨æˆ·æŸ¥è¯¢ç”Ÿæˆä¸“ä¸šçš„Elasticsearch DSLæç¤ºè¯ã€‚

**è¯·æ±‚ä½“ï¼š**
```json
{
  "query": "æœ€è¿‘5åˆ†é’Ÿå“ªä¸ªæœåŠ¡æœ€æ…¢?",
  "time_range": "5m",
  "timezone": "Asia/Shanghai",
  "language": "auto"
}
```

**å“åº”ï¼š**
```json
{
  "prompt": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„APM Elasticsearch DSLç”Ÿæˆä¸“å®¶...",
  "query_type": "performance",
  "time_range_info": "æ—¶é—´èŒƒå›´: 5m (2025-06-16 11:55 åˆ° 2025-06-16 12:00 (Asia/Shanghai))",
  "schema_info": {
    "transaction_index": "apm-*-transaction-*",
    "error_index": "apm-*-error-*",
    "common_fields": {...}
  }
}
```

#### 4. æ‰§è¡ŒDSLæŸ¥è¯¢

**POST** `/execute-query`

æ‰§è¡ŒElasticsearch DSLæŸ¥è¯¢å¹¶ç”Ÿæˆåˆ†ææç¤ºè¯ã€‚

**æ”¯æŒä¸‰ç§è¾“å…¥æ ¼å¼ï¼š**

**æ ¼å¼1ï¼šæ ‡å‡†DSLæ ¼å¼**
```json
{
  "dsl": {
    "size": 0,
    "query": {
      "bool": {
        "filter": [
          {
            "range": {
              "@timestamp": {
                "gte": "2025-06-16T11:55:00Z",
                "lte": "2025-06-16T12:00:00Z"
              }
            }
          }
        ]
      }
    },
    "aggs": {
      "services": {
        "terms": {
          "field": "service.name",
          "size": 10,
          "order": {"avg_duration": "desc"}
        },
        "aggs": {
          "avg_duration": {"avg": {"field": "transaction.duration.us"}}
        }
      }
    }
  },
  "original_query": "æœ€è¿‘5åˆ†é’Ÿå“ªä¸ªæœåŠ¡æœ€æ…¢?",
  "format": "summary"
}
```

**æ ¼å¼2ï¼šLLMæ ‡å‡†æ ¼å¼**
```json
{
  "query": {
    "size": 0,
    "query": {...},
    "aggs": {...}
  },
  "original_query": "æœ€è¿‘5åˆ†é’Ÿå“ªä¸ªæœåŠ¡æœ€æ…¢?",
  "format": "summary"
}
```

**æ ¼å¼3ï¼šMarkdownæ ¼å¼**
```json
{
  "content": "```json\n{\"size\": 0, \"query\": {...}}\n```",
  "original_query": "æœ€è¿‘5åˆ†é’Ÿå“ªä¸ªæœåŠ¡æœ€æ…¢?",
  "format": "summary"
}
```

**å“åº”ï¼š**
```json
{
  "raw_results": {
    "took": 15,
    "hits": {"total": {"value": 1250}},
    "aggregations": {
      "services": {
        "buckets": [
          {
            "key": "user-service",
            "doc_count": 320,
            "avg_duration": {"value": 145000.5}
          }
        ]
      }
    }
  },
  "analysis_prompt": "ä½ æ˜¯ä¸€ä¸ªAPMæ•°æ®åˆ†æä¸“å®¶ã€‚ç”¨æˆ·è¯¢é—®äº†å…³äºç³»ç»Ÿæ€§èƒ½çš„é—®é¢˜...",
  "query_executed_at": "2025-06-16T12:00:15.123456",
  "execution_success": true,
  "error_message": null
}
```

### è¾…åŠ©API

#### 5. æ¸…ç†Markdownæ ¼å¼

**POST** `/clean-dsl`

ä»LLMè¿”å›çš„Markdownä¸­æå–çº¯JSONã€‚

**è¯·æ±‚ä½“ï¼š**
```json
{
  "content": "```json\n{\"query\": {\"match_all\": {}}}\n```"
}
```

**å“åº”ï¼š**
```json
{
  "cleaned_dsl": {"query": {"match_all": {}}},
  "original_content": "```json\n{\"query\": {\"match_all\": {}}}\n```"
}
```

#### 6. å¥åº·æ£€æŸ¥

**GET** `/health`

æ£€æŸ¥æœåŠ¡å’ŒElasticsearchè¿æ¥çŠ¶æ€ã€‚

**å“åº”ï¼š**
```json
{
  "status": "healthy",
  "elasticsearch": "connected",
  "es_version": "7.17.0",
  "cluster_name": "elasticsearch"
}
```

#### 7. è°ƒè¯•API

- **GET** `/debug/indices` - æŸ¥çœ‹æ‰€æœ‰ESç´¢å¼•
- **GET** `/debug/mappings` - æŸ¥çœ‹APMç´¢å¼•å­—æ®µæ˜ å°„  
- **POST** `/debug/simple-query` - æ‰§è¡Œç®€å•æµ‹è¯•æŸ¥è¯¢

## æ—¶é—´èŒƒå›´æ”¯æŒ

### æ”¯æŒæ ¼å¼

| æ ¼å¼ç±»å‹ | ç¤ºä¾‹ | è¯´æ˜ |
|----------|------|------|
| åˆ†é’Ÿ | `5m`, `30min`, `15åˆ†é’Ÿ` | æœ€è¿‘Nåˆ†é’Ÿ |
| å°æ—¶ | `1h`, `2hour`, `3å°æ—¶` | æœ€è¿‘Nå°æ—¶ |
| å¤© | `1d`, `7day`, `30å¤©` | æœ€è¿‘Nå¤© |

### æ™ºèƒ½æ—¶é—´è¯æ±‡ç†è§£

| æ—¶é—´è¯æ±‡ | è‡ªåŠ¨æ˜ å°„ | è¯´æ˜ |
|----------|----------|------|
| "åˆšæ‰"ã€"åˆšåˆš" | 5-10åˆ†é’Ÿ | å®æ—¶é—®é¢˜æ’æŸ¥ |
| "æœ€è¿‘"ã€"è¿‘æœŸ" | 15åˆ†é’Ÿ-2å°æ—¶ | æ ¹æ®æŸ¥è¯¢ç±»å‹æ™ºèƒ½åˆ¤æ–­ |
| "ä»Šå¤©" | 1å¤© | å½“æ—¥æ•°æ®åˆ†æ |
| "æ˜¨å¤©" | æŸ¥çœ‹æ˜¨å¤©å…¨å¤© | å†å²å¯¹æ¯”åˆ†æ |
| "è¿™å‘¨"ã€"æœ¬å‘¨" | 7å¤© | è¶‹åŠ¿åˆ†æ |

### æŸ¥è¯¢ç±»å‹æ—¶é—´ç­–ç•¥

| æŸ¥è¯¢ç±»å‹ | é»˜è®¤æ—¶é—´èŒƒå›´ | ç­–ç•¥è¯´æ˜ |
|----------|--------------|----------|
| æ€§èƒ½é—®é¢˜ | 15-30åˆ†é’Ÿ | å®æ—¶æ€§è¦æ±‚é«˜ |
| é”™è¯¯åˆ†æ | 1-2å°æ—¶ | éœ€è¦è¶³å¤Ÿæ ·æœ¬ |
| è¶‹åŠ¿åˆ†æ | 1-7å¤© | é•¿æœŸæ¨¡å¼è¯†åˆ« |
| å®æ—¶ç›‘æ§ | 5-15åˆ†é’Ÿ | å³æ—¶çŠ¶æ€ |

## APMæ•°æ®ç»“æ„

### æ”¯æŒçš„ç´¢å¼•

| ç´¢å¼•æ¨¡å¼ | æ•°æ®ç±»å‹ | ç”¨é€” |
|----------|----------|------|
| `apm-*-transaction-*` | äº‹åŠ¡/è¯·æ±‚æ•°æ® | æ€§èƒ½åˆ†æä¸»è¦æ•°æ®æº |
| `apm-*-error-*` | é”™è¯¯/å¼‚å¸¸æ•°æ® | é”™è¯¯åˆ†æå’Œæ•…éšœæ’æŸ¥ |
| `apm-*-span-*` | åˆ†å¸ƒå¼è¿½è¸ªæ•°æ® | é“¾è·¯è¿½è¸ªåˆ†æ |
| `apm-*-metric-*` | ç³»ç»ŸæŒ‡æ ‡æ•°æ® | åŸºç¡€è®¾æ–½ç›‘æ§ |

### æ ¸å¿ƒå­—æ®µè¯¦è§£

#### äº‹åŠ¡å­—æ®µ
| å­—æ®µå | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|--------|------|------|------|
| `service.name` | keyword | æœåŠ¡åç§° | `user-service` |
| `service.version` | keyword | æœåŠ¡ç‰ˆæœ¬ | `1.2.3` |
| `transaction.name` | keyword | æ¥å£åç§° | `GET /api/users` |
| `transaction.type` | keyword | äº‹åŠ¡ç±»å‹ | `request` |
| `transaction.duration.us` | long | å“åº”æ—¶é—´(å¾®ç§’) | `150000` |
| `transaction.result` | keyword | äº‹åŠ¡ç»“æœ | `success` |

#### æ—¶é—´å’ŒçŠ¶æ€å­—æ®µ
| å­—æ®µå | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|--------|------|------|------|
| `@timestamp` | date | æ—¶é—´æˆ³ | `2025-06-16T12:00:00.000Z` |
| `event.outcome` | keyword | äº‹ä»¶ç»“æœ | `success/failure` |
| `http.response.status_code` | long | HTTPçŠ¶æ€ç  | `200` |
| `http.request.method` | keyword | HTTPæ–¹æ³• | `GET` |
| `url.path` | keyword | è¯·æ±‚è·¯å¾„ | `/api/users` |

#### é”™è¯¯å­—æ®µ
| å­—æ®µå | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|--------|------|------|------|
| `error.id` | keyword | é”™è¯¯ID | `abc123` |
| `error.exception.type` | keyword | å¼‚å¸¸ç±»å‹ | `NullPointerException` |
| `error.exception.message` | text | é”™è¯¯ä¿¡æ¯ | `Connection timeout` |
| `error.culprit` | keyword | é”™è¯¯ä½ç½® | `UserService.getUser` |

#### åŸºç¡€è®¾æ–½å­—æ®µ
| å­—æ®µå | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|--------|------|------|------|
| `host.name` | keyword | ä¸»æœºå | `app-server-01` |
| `host.ip` | ip | ä¸»æœºIP | `192.168.1.100` |
| `container.id` | keyword | å®¹å™¨ID | `abc123def456` |
| `kubernetes.pod.name` | keyword | K8s Podåç§° | `user-service-pod-1` |

## æŸ¥è¯¢ç¤ºä¾‹ä¸æœ€ä½³å®è·µ

### 1. æ€§èƒ½åˆ†ææŸ¥è¯¢

#### æœåŠ¡æ€§èƒ½æ’å
```bash
curl -X POST "http://localhost:8000/generate-dsl" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "æœ€è¿‘1å°æ—¶å“ªä¸ªæœåŠ¡å“åº”æœ€æ…¢?",
    "time_range": "1h",
    "timezone": "Asia/Shanghai"
  }'
```

#### æ¥å£æ€§èƒ½åˆ†æ
```bash
curl -X POST "http://localhost:8000/generate-dsl" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "ç”¨æˆ·æœåŠ¡çš„æ¥å£å“åº”æ—¶é—´åˆ†æ",
    "time_range": "30m"
  }'
```

#### å“åº”æ—¶é—´åˆ†å¸ƒ
```bash
curl -X POST "http://localhost:8000/generate-dsl" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "æ˜¾ç¤ºæ‰€æœ‰æœåŠ¡çš„P95å“åº”æ—¶é—´",
    "time_range": "2h"
  }'
```

### 2. é”™è¯¯åˆ†ææŸ¥è¯¢

#### é”™è¯¯ç»Ÿè®¡
```bash
curl -X POST "http://localhost:8000/generate-dsl" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "ä»Šå¤©å“ªä¸ªæ¥å£æŠ¥é”™æœ€å¤š?",
    "time_range": "1d"
  }'
```

#### é”™è¯¯ç±»å‹åˆ†æ
```bash
curl -X POST "http://localhost:8000/generate-dsl" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "æœ€è¿‘2å°æ—¶çš„é”™è¯¯ç±»å‹åˆ†å¸ƒ",
    "time_range": "2h"
  }'
```

#### é”™è¯¯ç‡åˆ†æ
```bash
curl -X POST "http://localhost:8000/generate-dsl" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "ç”¨æˆ·æœåŠ¡çš„é”™è¯¯ç‡è¶‹åŠ¿",
    "time_range": "4h"
  }'
```

### 3. æµé‡åˆ†ææŸ¥è¯¢

#### è¯·æ±‚é‡ç»Ÿè®¡
```bash
curl -X POST "http://localhost:8000/generate-dsl" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "ç”¨æˆ·æœåŠ¡è¿‡å»30åˆ†é’Ÿçš„è¯·æ±‚é‡è¶‹åŠ¿",
    "time_range": "30m"
  }'
```

#### QPSåˆ†æ
```bash
curl -X POST "http://localhost:8000/generate-dsl" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "å„æœåŠ¡çš„QPSæ’å",
    "time_range": "15m"
  }'
```

### 4. çŠ¶æ€ç åˆ†æ

#### HTTPçŠ¶æ€ç åˆ†å¸ƒ
```bash
curl -X POST "http://localhost:8000/generate-dsl" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "æœ€è¿‘1å°æ—¶4xxå’Œ5xxçŠ¶æ€ç ç»Ÿè®¡",
    "time_range": "1h"
  }'
```

### 5. å¤åˆæŸ¥è¯¢

#### ç»¼åˆå¥åº·åº¦åˆ†æ
```bash
curl -X POST "http://localhost:8000/generate-dsl" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "ç”¨æˆ·æœåŠ¡çš„ç»¼åˆæ€§èƒ½æŒ‡æ ‡ï¼šå“åº”æ—¶é—´ã€é”™è¯¯ç‡ã€è¯·æ±‚é‡",
    "time_range": "1h"
  }'
```

## ä¸Difyé›†æˆ

### 1. ç®€åŒ–å·¥ä½œæµé…ç½®

#### èŠ‚ç‚¹é…ç½®
1. **èŠ‚ç‚¹1 - ç”ŸæˆDSL**ï¼šè°ƒç”¨ `/generate-dsl` API
2. **èŠ‚ç‚¹2 - LLMå¤„ç†**ï¼šä½¿ç”¨è¿”å›çš„promptç”ŸæˆDSL
3. **èŠ‚ç‚¹3 - æ‰§è¡ŒæŸ¥è¯¢**ï¼šè°ƒç”¨ `/execute-query` API
4. **èŠ‚ç‚¹4 - ç»“æœåˆ†æ**ï¼šä½¿ç”¨è¿”å›çš„analysis_promptåˆ†æç»“æœ
5. **èŠ‚ç‚¹5 - è¿”å›ç­”æ¡ˆ**ï¼šè¿”å›æœ€ç»ˆåˆ†æç»“æœ

#### Dify HTTPèŠ‚ç‚¹é…ç½®

**ç”ŸæˆDSLèŠ‚ç‚¹ï¼š**
```yaml
URL: http://your-api-host:8000/generate-dsl
Method: POST
Headers: 
  Content-Type: application/json
Body: |
  {
    "query": "{{user_input}}",
    "time_range": "15m",
    "timezone": "Asia/Shanghai"
  }
Output Variables:
  - dsl_prompt: {{response.prompt}}
  - query_type: {{response.query_type}}
```

**æ‰§è¡ŒæŸ¥è¯¢èŠ‚ç‚¹ï¼š**
```yaml
URL: http://your-api-host:8000/execute-query
Method: POST
Headers:
  Content-Type: application/json
Body: |
  {
    "content": "{{llm_dsl_output}}",
    "original_query": "{{user_input}}",
    "format": "summary"
  }
Output Variables:
  - analysis_prompt: {{response.analysis_prompt}}
  - execution_success: {{response.execution_success}}
  - error_message: {{response.error_message}}
```

### 2. æ—¶é—´æ„ŸçŸ¥å·¥ä½œæµé…ç½®

#### å®Œæ•´èŠ‚ç‚¹æµç¨‹
1. **æ—¶é—´åˆ†æ**: `/analyze-time-context`
2. **LLMæ—¶é—´å¤„ç†**: åˆ†ææ—¶é—´éœ€æ±‚
3. **æ—¶é—´ç»“æœå¤„ç†**: `/process-time-analysis`
4. **DSLç”Ÿæˆ**: `/generate-dsl` (ä½¿ç”¨åˆ†æçš„æ—¶é—´èŒƒå›´)
5. **LLM DSLç”Ÿæˆ**: ç”ŸæˆæŸ¥è¯¢DSL
6. **æ‰§è¡ŒæŸ¥è¯¢**: `/execute-query`
7. **ç»“æœåˆ†æ**: LLMæœ€ç»ˆåˆ†æ

#### èŠ‚ç‚¹é…ç½®ç¤ºä¾‹

**æ—¶é—´åˆ†æèŠ‚ç‚¹ï¼š**
```yaml
URL: http://your-api-host:8000/analyze-time-context
Method: POST
Body: |
  {
    "query": "{{user_input}}",
    "timezone": "Asia/Shanghai"
  }
```

**æ—¶é—´ç»“æœå¤„ç†èŠ‚ç‚¹ï¼š**
```yaml
URL: http://your-api-host:8000/process-time-analysis
Method: POST
Body: |
  {
    "content": "{{llm_time_analysis_result}}"
  }
```

### 3. é”™è¯¯å¤„ç†é…ç½®

åœ¨Difyä¸­æ·»åŠ æ¡ä»¶åˆ¤æ–­èŠ‚ç‚¹ï¼š

```yaml
# æ£€æŸ¥æ‰§è¡Œæ˜¯å¦æˆåŠŸ
IF: {{execution_success}} == true
THEN: ç»§ç»­ç»“æœåˆ†æ
ELSE: è¿”å›é”™è¯¯ä¿¡æ¯ "æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {{error_message}}"
```

## ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### 1. ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env æ–‡ä»¶
ES_HOST=http://your-production-elasticsearch:9200
TZ=Asia/Shanghai
PYTHONPATH=/app
WORKERS=4
```

### 2. Docker Composeéƒ¨ç½²

```yaml
# docker-compose.yml
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - es_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  apm-text2dsl:
    build: .
    container_name: apm-text2dsl
    ports:
      - "8000:8000"
    environment:
      - ES_HOST=http://elasticsearch:9200
      - TZ=Asia/Shanghai
    restart: unless-stopped
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

volumes:
  es_data:
    driver: local

networks:
  default:
    driver: bridge
```

### 3. åå‘ä»£ç†é…ç½®

#### Nginxé…ç½®
```nginx
upstream apm_text2dsl {
    server localhost:8000 max_fails=3 fail_timeout=30s;
}

server {
    listen 80;
    server_name apm-api.yourdomain.com;

    # APIè·¯ç”±
    location /apm-api/ {
        proxy_pass http://apm_text2dsl/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # è¶…æ—¶é…ç½®
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
        
        # ç¼“å†²é…ç½®
        proxy_buffering on;
        proxy_buffer_size 8k;
        proxy_buffers 16 8k;
        
        # é”™è¯¯é¡µé¢
        proxy_intercept_errors on;
        error_page 502 503 504 /50x.html;
    }

    # å¥åº·æ£€æŸ¥
    location /health {
        proxy_pass http://apm_text2dsl/health;
        access_log off;
    }

    # é™æ€é”™è¯¯é¡µé¢
    location = /50x.html {
        root /usr/share/nginx/html;
    }
}
```

#### Apacheé…ç½®
```apache
<VirtualHost *:80>
    ServerName apm-api.yourdomain.com
    
    ProxyPreserveHost On
    ProxyRequests Off
    
    ProxyPass /apm-api/ http://localhost:8000/
    ProxyPassReverse /apm-api/ http://localhost:8000/
    
    ProxyTimeout 60
    ProxyBadHeader Ignore
</VirtualHost>
```

### 4. ç›‘æ§é…ç½®

#### æ—¥å¿—é…ç½®
```yaml
# docker-compose.yml ä¸­æ·»åŠ æ—¥å¿—é…ç½®
services:
  apm-text2dsl:
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"
```

#### Prometheusç›‘æ§
```yaml
# åœ¨åº”ç”¨ä¸­æ·»åŠ metricsç«¯ç‚¹
@app.get("/metrics")
async def metrics():
    return {
        "requests_total": request_count,
        "requests_failed": failed_count,
        "avg_response_time": avg_response_time
    }
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜è¯Šæ–­

#### 1. ESè¿æ¥é—®é¢˜

**ç—‡çŠ¶ï¼š**
- `{"status": "unhealthy", "elasticsearch": "disconnected"}`
- Connection refusedé”™è¯¯

**è¯Šæ–­æ­¥éª¤ï¼š**
```bash
# 1. æ£€æŸ¥ESæœåŠ¡çŠ¶æ€
curl http://your-elasticsearch:9200
curl http://your-elasticsearch:9200/_cluster/health

# 2. æ£€æŸ¥ç½‘ç»œè¿é€šæ€§
docker exec apm-text2dsl ping elasticsearch
docker exec apm-text2dsl nslookup elasticsearch

# 3. æ£€æŸ¥å®¹å™¨ç½‘ç»œ
docker network ls
docker network inspect bridge

# 4. æ£€æŸ¥ESé…ç½®
docker logs elasticsearch | tail -50
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# é‡å¯ESæœåŠ¡
docker restart elasticsearch

# æ£€æŸ¥ESå†…å­˜é…ç½®
docker stats elasticsearch

# ä¿®æ­£ES_HOSTé…ç½®
docker stop apm-text2dsl
docker run -d --name apm-text2dsl -p 8000:8000 \
  -e ES_HOST=http://correct-elasticsearch-host:9200 \
  apm-text2dsl:latest
```

#### 2. APMç´¢å¼•é—®é¢˜

**ç—‡çŠ¶ï¼š**
- `index_not_found_exception`
- ç©ºçš„æŸ¥è¯¢ç»“æœ

**è¯Šæ–­æ­¥éª¤ï¼š**
```bash
# 1. æ£€æŸ¥APMç´¢å¼•
curl http://localhost:8000/debug/indices
curl "http://your-elasticsearch:9200/_cat/indices/apm*?v"

# 2. æ£€æŸ¥ç´¢å¼•ç»“æ„
curl http://localhost:8000/debug/mappings

# 3. æµ‹è¯•ç®€å•æŸ¥è¯¢
curl -X POST http://localhost:8000/debug/simple-query
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# å¦‚æœæ²¡æœ‰APMæ•°æ®ï¼Œåˆ›å»ºæµ‹è¯•æ•°æ®
curl -X POST "http://your-elasticsearch:9200/apm-test-transaction-2025.06.16/_doc" \
-H "Content-Type: application/json" \
-d '{
  "service.name": "test-service",
  "transaction.name": "GET /test",
  "transaction.duration.us": 150000,
  "@timestamp": "2025-06-16T12:00:00.000Z",
  "event.outcome": "success"
}'
```

#### 3. DSLè¯­æ³•é”™è¯¯

**ç—‡çŠ¶ï¼š**
- `search_phase_execution_exception`
- `parsing_exception`

**å¸¸è§é”™è¯¯åŠè§£å†³ï¼š**

**é”™è¯¯1ï¼šç™¾åˆ†ä½æ•°æ’åº**
```json
// âŒ é”™è¯¯
"order": {"p95_duration": "desc"}

// âœ… æ­£ç¡®  
"order": {"avg_duration": "desc"}
```

**é”™è¯¯2ï¼šæ—¶é—´æ ¼å¼é—®é¢˜**
```json
// âŒ é”™è¯¯
"@timestamp": {"gte": "now-1h"}

// âœ… æ­£ç¡®
"@timestamp": {
  "gte": "2025-06-16T11:00:00Z",
  "lte": "2025-06-16T12:00:00Z",
  "format": "strict_date_optional_time"
}
```

**é”™è¯¯3ï¼šå­—æ®µåé”™è¯¯**
```bash
# æ£€æŸ¥æ­£ç¡®çš„å­—æ®µå
curl http://localhost:8000/debug/mappings
```

#### 4. æ€§èƒ½é—®é¢˜

**ç—‡çŠ¶ï¼š**
- æŸ¥è¯¢è¶…æ—¶
- å“åº”ç¼“æ…¢

**ä¼˜åŒ–æ–¹æ¡ˆï¼š**
```json
// æŸ¥è¯¢ä¼˜åŒ–
{
  "size": 0,  // ä¸è¿”å›åŸå§‹æ–‡æ¡£
  "track_total_hits": false,  // ä¸ç²¾ç¡®è®¡ç®—æ€»æ•°
  "timeout": "30s",  // è®¾ç½®è¶…æ—¶
  "query": {
    "bool": {
      "filter": [  // ä½¿ç”¨filterè€Œémustï¼Œæå‡æ€§èƒ½
        {"range": {"@timestamp": {"gte": "now-1h"}}}
      ]
    }
  }
}
```

**ESé›†ç¾¤ä¼˜åŒ–ï¼š**
```bash
# å¢åŠ ESå†…å­˜
docker run -d \
  --name elasticsearch \
  -e "ES_JAVA_OPTS=-Xms4g -Xmx4g" \
  elasticsearch:7.17.0

# ä¼˜åŒ–ESé…ç½®
curl -X PUT "http://your-elasticsearch:9200/_cluster/settings" \
-H "Content-Type: application/json" \
-d '{
  "persistent": {
    "search.max_buckets": 65536,
    "indices.queries.cache.size": "20%"
  }
}'
```

#### 5. å†…å­˜é—®é¢˜

**ç—‡çŠ¶ï¼š**
- å®¹å™¨é‡å¯
- Out of Memoryé”™è¯¯

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# å¢åŠ å®¹å™¨å†…å­˜é™åˆ¶
docker run -d \
  --name apm-text2dsl \
  --memory=2g \
  --memory-swap=4g \
  -p 8000:8000 \
  apm-text2dsl:latest

# ç›‘æ§å†…å­˜ä½¿ç”¨
docker stats apm-text2dsl
```

#### 6. æ—¶åŒºé—®é¢˜

**ç—‡çŠ¶ï¼š**
- æŸ¥è¯¢ç»“æœæ—¶é—´ä¸æ­£ç¡®
- æ—¶é—´èŒƒå›´é”™è¯¯

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# è®¾ç½®å®¹å™¨æ—¶åŒº
docker run -d \
  --name apm-text2dsl \
  -e TZ=Asia/Shanghai \
  -p 8000:8000 \
  apm-text2dsl:latest

# åœ¨APIè°ƒç”¨ä¸­æ˜ç¡®æŒ‡å®šæ—¶åŒº
{
  "query": "æœ€è¿‘1å°æ—¶çš„æ•°æ®",
  "timezone": "Asia/Shanghai"
}
```

### è°ƒè¯•å·¥å…·

#### 1. æ—¥å¿—åˆ†æ
```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
docker logs -f apm-text2dsl

# æŸ¥çœ‹ESæŸ¥è¯¢æ—¥å¿—
docker logs -f apm-text2dsl | grep "æŸ¥è¯¢DSL"

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
docker logs apm-text2dsl 2>&1 | grep -i error
```

#### 2. æ€§èƒ½ç›‘æ§
```bash
# å®¹å™¨èµ„æºä½¿ç”¨
docker stats

# ESé›†ç¾¤çŠ¶æ€
curl "http://your-elasticsearch:9200/_cluster/stats?pretty"

# APIå“åº”æ—¶é—´æµ‹è¯•
time curl -X POST "http://localhost:8000/execute-query" \
  -H "Content-Type: application/json" \
  -d '{"dsl": {...}, "original_query": "test"}'
```

#### 3. ç½‘ç»œè¯Šæ–­
```bash
# æµ‹è¯•ç½‘ç»œè¿é€šæ€§
docker exec apm-text2dsl ping elasticsearch
docker exec apm-text2dsl telnet elasticsearch 9200

# æ£€æŸ¥DNSè§£æ
docker exec apm-text2dsl nslookup elasticsearch
```

## æ€§èƒ½ä¼˜åŒ–æŒ‡å—

### 1. ESæŸ¥è¯¢ä¼˜åŒ–

#### æŸ¥è¯¢ç»“æ„ä¼˜åŒ–
```json
{
  "size": 0,
  "_source": false,
  "track_total_hits": false,
  "timeout": "30s",
  "query": {
    "bool": {
      "filter": [  // ä½¿ç”¨filterï¼Œä¸è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
        {"term": {"service.name": "user-service"}},
        {"range": {"@timestamp": {"gte": "now-1h"}}}
      ]
    }
  }
}
```

#### èšåˆä¼˜åŒ–
```json
{
  "aggs": {
    "services": {
      "terms": {
        "field": "service.name",
        "size": 10,  // é™åˆ¶èšåˆå¤§å°
        "execution_hint": "map"  // ä¼˜åŒ–æ‰§è¡Œæ–¹å¼
      }
    }
  }
}
```

### 2. åº”ç”¨å±‚ä¼˜åŒ–

#### è¿æ¥æ± é…ç½®
```python
# åœ¨main.pyä¸­ä¼˜åŒ–ESå®¢æˆ·ç«¯
es_client = Elasticsearch(
    [ES_URL],
    verify_certs=False,
    timeout=30,
    max_retries=3,
    retry_on_timeout=True,
    http_compress=True,
    maxsize=25  // è¿æ¥æ± å¤§å°
)
```

#### ç¼“å­˜ç­–ç•¥
```python
import functools
import time
from typing import Dict, Any

# ç®€å•çš„å†…å­˜ç¼“å­˜
cache = {}
CACHE_TTL = 300  # 5åˆ†é’Ÿ

def cached_query(cache_key: str, ttl: int = CACHE_TTL):
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            now = time.time()
            if cache_key in cache:
                result, timestamp = cache[cache_key]
                if now - timestamp < ttl:
                    return result
            
            result = func(*args, **kwargs)
            cache[cache_key] = (result, now)
            return result
        return wrapper
    return decorator
```

### 3. éƒ¨ç½²ä¼˜åŒ–

#### èµ„æºé…ç½®
```yaml
# docker-compose.yml
services:
  elasticsearch:
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
    environment:
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"

  apm-text2dsl:
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
```

#### è´Ÿè½½å‡è¡¡
```nginx
upstream apm_backend {
    server apm-text2dsl-1:8000 weight=1 max_fails=3 fail_timeout=30s;
    server apm-text2dsl-2:8000 weight=1 max_fails=3 fail_timeout=30s;
    keepalive 32;
}

server {
    location /apm-api/ {
        proxy_pass http://apm_backend/;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
    }
}
```

## å¼€å‘æŒ‡å—

### æœ¬åœ°å¼€å‘ç¯å¢ƒ

#### ç¯å¢ƒæ­å»º
```bash
# 1. å…‹éš†ä»£ç 
git clone <your-repo-url>
cd apm-text2dsl

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. å¯åŠ¨ES (å¦‚æœéœ€è¦)
docker run -d --name dev-elasticsearch \
  -p 9200:9200 \
  -e "discovery.type=single-node" \
  elasticsearch:7.17.0

# 5. è¿è¡Œå¼€å‘æœåŠ¡å™¨
export ES_HOST=http://localhost:9200
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

#### å¼€å‘å·¥å…·é…ç½®

**VSCodeé…ç½® (.vscode/settings.json):**
```json
{
  "python.defaultInterpreterPath": "./venv/bin/python",
  "python.linting.enabled": true,
  "python.linting.pylintEnabled": true,
  "python.formatting.provider": "black",
  "python.formatting.blackArgs": ["--line-length", "100"]
}
```

**pytesté…ç½® (pytest.ini):**
```ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = -v --tb=short
```

### ä»£ç ç»“æ„

```
apm-text2dsl/
â”œâ”€â”€ main.py                 # ä¸»ç¨‹åºæ–‡ä»¶
â”œâ”€â”€ requirements.txt        # Pythonä¾èµ–
â”œâ”€â”€ Dockerfile             # Dockeræ„å»ºæ–‡ä»¶
â”œâ”€â”€ docker-compose.yml     # å®¹å™¨ç¼–æ’é…ç½®
â”œâ”€â”€ README.md              # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ .env.example           # ç¯å¢ƒå˜é‡ç¤ºä¾‹
â”œâ”€â”€ .gitignore             # Gitå¿½ç•¥æ–‡ä»¶
â”œâ”€â”€ tests/                 # æµ‹è¯•æ–‡ä»¶
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_dsl_generation.py
â”‚   â””â”€â”€ test_time_parsing.py
â”œâ”€â”€ docs/                  # è¯¦ç»†æ–‡æ¡£
â”‚   â”œâ”€â”€ api.md
â”‚   â”œâ”€â”€ deployment.md
â”‚   â””â”€â”€ troubleshooting.md
â””â”€â”€ scripts/               # å·¥å…·è„šæœ¬
    â”œâ”€â”€ setup.sh
    â”œâ”€â”€ test_data.py
    â””â”€â”€ health_check.sh
```

### æ‰©å±•å¼€å‘

#### 1. æ·»åŠ æ–°çš„æŸ¥è¯¢ç±»å‹

**ä¿®æ”¹æŸ¥è¯¢ç±»å‹è¯†åˆ«ï¼š**
```python
def determine_query_type(query: str) -> str:
    """æ ¹æ®ç”¨æˆ·æŸ¥è¯¢ç¡®å®šæŸ¥è¯¢ç±»å‹"""
    query_lower = query.lower()

    # æ·»åŠ æ–°çš„æŸ¥è¯¢ç±»å‹
    if any(word in query_lower for word in ['ååé‡', 'throughput', 'tps']):
        return "throughput"
    elif any(word in query_lower for word in ['å®¹é‡', 'capacity', 'è´Ÿè½½']):
        return "capacity"
    # ... ç°æœ‰é€»è¾‘
```

**æ·»åŠ å¯¹åº”çš„DSLæ¨¡æ¿ï¼š**
```python
def generate_dsl_prompt(query: str, time_range: str, timezone: str = "UTC") -> str:
    # åœ¨promptä¸­æ·»åŠ æ–°çš„æŸ¥è¯¢æ¨¡æ¿
    throughput_template = """
F. ååé‡åˆ†æ:
{
  "aggs": {
    "timeline": {
      "date_histogram": {
        "field": "@timestamp",
        "fixed_interval": "1m"
      },
      "aggs": {
        "tps": {
          "rate": {
            "field": "@timestamp",
            "unit": "second"
          }
        }
      }
    }
  }
}
"""
```

#### 2. æ”¯æŒæ–°çš„æ—¶é—´æ ¼å¼

**æ‰©å±•æ—¶é—´è§£æå‡½æ•°ï¼š**
```python
def parse_time_range(time_str: str, timezone: str = "UTC") -> tuple:
    """è§£ææ—¶é—´èŒƒå›´ï¼Œæ”¯æŒæ›´å¤šæ ¼å¼"""
    
    # æ·»åŠ æ–°çš„æ—¶é—´æ ¼å¼
    week_pattern = r'(\d+)\s*(w|week|å‘¨)'
    month_pattern = r'(\d+)\s*(M|month|æœˆ)'
    
    if re.search(week_pattern, time_str.lower()):
        match = re.search(week_pattern, time_str.lower())
        weeks = int(match.group(1))
        delta = timedelta(weeks=weeks)
    elif re.search(month_pattern, time_str.lower()):
        match = re.search(month_pattern, time_str.lower())
        months = int(match.group(1))
        delta = timedelta(days=months * 30)  # è¿‘ä¼¼å€¼
    
    # ... ç°æœ‰é€»è¾‘
```

#### 3. ä¼˜åŒ–ç»“æœåˆ†æ

**å¢å¼ºåˆ†ææç¤ºè¯ï¼š**
```python
def generate_analysis_prompt(original_query: str, es_results: Dict[Any, Any], query_type: str) -> str:
    """ç”Ÿæˆæ›´æ™ºèƒ½çš„åˆ†ææç¤ºè¯"""
    
    # æ ¹æ®æŸ¥è¯¢ç±»å‹æä¾›ä¸“ä¸šå»ºè®®
    analysis_context = {
        "performance": "å…³æ³¨å“åº”æ—¶é—´åˆ†å¸ƒã€å¼‚å¸¸å€¼æ£€æµ‹ã€æ€§èƒ½ç“¶é¢ˆè¯†åˆ«",
        "error": "åˆ†æé”™è¯¯æ¨¡å¼ã€å½±å“èŒƒå›´ã€æ ¹å› åˆ†æå»ºè®®",
        "throughput": "è¯„ä¼°ç³»ç»Ÿå®¹é‡ã€æµé‡è¶‹åŠ¿ã€æ‰©å®¹å»ºè®®",
        # ... æ·»åŠ æ›´å¤šä¸Šä¸‹æ–‡
    }
    
    context = analysis_context.get(query_type, "é€šç”¨APMæ•°æ®åˆ†æ")
    
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„APMæ•°æ®åˆ†æä¸“å®¶ã€‚
åˆ†æé‡ç‚¹: {context}

ç”¨æˆ·åŸå§‹é—®é¢˜: {original_query}
...
"""
```

### æµ‹è¯•å¼€å‘

#### å•å…ƒæµ‹è¯•ç¤ºä¾‹
```python
# tests/test_time_parsing.py
import pytest
from datetime import datetime, timedelta
from main import parse_time_range

class TestTimeParsing:
    def test_minute_parsing(self):
        start, end = parse_time_range("5m")
        duration = end - start
        assert duration.total_seconds() == 300  # 5 minutes

    def test_chinese_time_parsing(self):
        start, end = parse_time_range("30åˆ†é’Ÿ")
        duration = end - start
        assert duration.total_seconds() == 1800  # 30 minutes

    def test_timezone_awareness(self):
        start, end = parse_time_range("1h", "Asia/Shanghai")
        # éªŒè¯æ—¶åŒºæ­£ç¡®æ€§
        assert start.tzinfo is not None
```

#### é›†æˆæµ‹è¯•ç¤ºä¾‹
```python
# tests/test_api.py
import pytest
from fastapi.testclient import TestClient
from main import app

client = TestClient(app)

class TestAPI:
    def test_health_check(self):
        response = client.get("/health")
        assert response.status_code == 200

    def test_generate_dsl(self):
        response = client.post("/generate-dsl", json={
            "query": "æœ€è¿‘5åˆ†é’Ÿå“ªä¸ªæœåŠ¡æœ€æ…¢",
            "time_range": "5m"
        })
        assert response.status_code == 200
        data = response.json()
        assert "prompt" in data
        assert "query_type" in data
```

#### æ€§èƒ½æµ‹è¯•
```python
# tests/test_performance.py
import time
import pytest
from fastapi.testclient import TestClient

def test_api_response_time():
    start_time = time.time()
    response = client.post("/generate-dsl", json={
        "query": "æ€§èƒ½æµ‹è¯•æŸ¥è¯¢"
    })
    end_time = time.time()
    
    assert response.status_code == 200
    assert (end_time - start_time) < 1.0  # å“åº”æ—¶é—´å°äº1ç§’
```

## é«˜çº§ç‰¹æ€§

### 1. æ™ºèƒ½æ—¶é—´èŒƒå›´æ¨è

ç³»ç»Ÿä¼šæ ¹æ®æŸ¥è¯¢å†…å®¹æ™ºèƒ½æ¨èæœ€åˆé€‚çš„æ—¶é—´èŒƒå›´ï¼š

- **å®æ—¶ç›‘æ§ç±»æŸ¥è¯¢**: 5-15åˆ†é’Ÿ
- **æ€§èƒ½é—®é¢˜æ’æŸ¥**: 15-30åˆ†é’Ÿ  
- **é”™è¯¯åˆ†æ**: 1-2å°æ—¶
- **è¶‹åŠ¿åˆ†æ**: 1-7å¤©
- **å®¹é‡è§„åˆ’**: 7-30å¤©

### 2. å¤šç»´åº¦æŸ¥è¯¢æ”¯æŒ

æ”¯æŒå¤åˆæŸ¥è¯¢æ¡ä»¶ï¼š
- æœåŠ¡ + æ¥å£ + æ—¶é—´èŒƒå›´
- é”™è¯¯ç±»å‹ + å½±å“èŒƒå›´ + è¶‹åŠ¿åˆ†æ
- æ€§èƒ½æŒ‡æ ‡ + ä¸šåŠ¡æŒ‡æ ‡ + å¯¹æ¯”åˆ†æ

### 3. è‡ªé€‚åº”èšåˆç­–ç•¥

æ ¹æ®æ•°æ®é‡è‡ªåŠ¨è°ƒæ•´èšåˆç­–ç•¥ï¼š
- å°æ•°æ®é‡: è¯¦ç»†åˆ†æ
- ä¸­ç­‰æ•°æ®é‡: é‡‡æ ·åˆ†æ
- å¤§æ•°æ®é‡: æ™ºèƒ½é™é‡‡æ ·

### 4. é”™è¯¯æ¢å¤æœºåˆ¶

- è‡ªåŠ¨é‡è¯•æœºåˆ¶
- é™çº§æŸ¥è¯¢ç­–ç•¥
- ç¼“å­˜å®¹é”™æœºåˆ¶

## è·¯çº¿å›¾

### v1.1 (è®¡åˆ’ä¸­)
- [ ] æ”¯æŒå¤šESé›†ç¾¤
- [ ] å¢åŠ æŸ¥è¯¢ç¼“å­˜
- [ ] æ”¯æŒè‡ªå®šä¹‰èšåˆæ¨¡æ¿
- [ ] APIå¯†é’¥è®¤è¯

### v1.2 (è®¡åˆ’ä¸­)
- [ ] æ”¯æŒGrafanaé›†æˆ
- [ ] å®æ—¶æµå¼æŸ¥è¯¢
- [ ] æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹
- [ ] å¤šç§Ÿæˆ·æ”¯æŒ

### v2.0 (è¿œæœŸè§„åˆ’)
- [ ] å¯è§†åŒ–æŸ¥è¯¢æ„å»ºå™¨
- [ ] è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆ
- [ ] å‘Šè­¦è§„åˆ™ç”Ÿæˆ
- [ ] å®Œæ•´çš„RBACæƒé™ä½“ç³»

## è®¸å¯è¯

MIT License

Copyright (c) 2025 APM Text2DSL Project

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

## è´¡çŒ®æŒ‡å—

### å¦‚ä½•è´¡çŒ®

1. **Forké¡¹ç›®**
2. **åˆ›å»ºç‰¹æ€§åˆ†æ”¯** (`git checkout -b feature/AmazingFeature`)
3. **æäº¤æ›´æ”¹** (`git commit -m 'Add some AmazingFeature'`)
4. **æ¨é€åˆ°åˆ†æ”¯** (`git push origin feature/AmazingFeature`)
5. **å¼€å¯Pull Request**

### è´¡çŒ®è§„èŒƒ

- éµå¾ªPEP 8ä»£ç è§„èŒƒ
- æ·»åŠ é€‚å½“çš„æµ‹è¯•ç”¨ä¾‹
- æ›´æ–°ç›¸å…³æ–‡æ¡£
- ç¡®ä¿æ‰€æœ‰æµ‹è¯•é€šè¿‡

### é—®é¢˜æŠ¥å‘Š

ä½¿ç”¨GitHub IssuesæŠ¥å‘Šé—®é¢˜æ—¶ï¼Œè¯·åŒ…å«ï¼š
- é—®é¢˜è¯¦ç»†æè¿°
- é‡ç°æ­¥éª¤
- é¢„æœŸç»“æœ vs å®é™…ç»“æœ
- ç¯å¢ƒä¿¡æ¯ (OS, Pythonç‰ˆæœ¬, ESç‰ˆæœ¬ç­‰)
- ç›¸å…³æ—¥å¿—ä¿¡æ¯

## æ”¯æŒä¸ç¤¾åŒº

### è·å–å¸®åŠ©

- **æ–‡æ¡£**: æŸ¥çœ‹æœ¬READMEå’Œdocs/ç›®å½•
- **Issues**: GitHub Issuesé¡µé¢
- **è®¨è®º**: GitHub Discussions
- **é‚®ä»¶**: å‘é€é‚®ä»¶è‡³ support@yourcompany.com

### ç¤¾åŒºèµ„æº

- **ç¤ºä¾‹é¡¹ç›®**: [examples/](examples/)
- **æœ€ä½³å®è·µ**: [docs/best-practices.md](docs/best-practices.md)
- **å¸¸è§é—®é¢˜**: [docs/faq.md](docs/faq.md)
- **è§†é¢‘æ•™ç¨‹**: [å¾…æ·»åŠ ]

---

**ç‰ˆæœ¬ï¼š** 1.0.0  
**ç»´æŠ¤è€…ï¼š** å†…ç½‘å¼€å‘å›¢é˜Ÿ  
**æœ€åæ›´æ–°ï¼š** 2025-06-16  
**æ–‡æ¡£ç‰ˆæœ¬ï¼š** å®Œæ•´ç‰ˆ v1.0

---

### å¿«é€Ÿé“¾æ¥

- [APIæ–‡æ¡£](#api-æ–‡æ¡£)
- [éƒ¨ç½²æŒ‡å—](#ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [å¼€å‘æŒ‡å—](#å¼€å‘æŒ‡å—)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–æŒ‡å—)